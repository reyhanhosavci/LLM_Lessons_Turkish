import re  # "re" modÃ¼lÃ¼, metinleri dÃ¼zenli ifadelerle (regex) parÃ§alamamÄ±za yardÄ±mcÄ± olur.

# ğŸ”¹ Bu sÄ±nÄ±f, Ã§ok basit bir "tokenizer" Ã¶rneÄŸi.
# Yani metni kelimelere veya sembollere ayÄ±rÄ±yor (encode),
# sonra da o sayÄ±lardan tekrar metin oluÅŸturabiliyor (decode).

class SimpleTokenizerV1:
    def __init__(self, vocab):
        # vocab: kelimelerle (ya da sembollerle) sayÄ±lar arasÄ±ndaki eÅŸleÅŸmeyi iÃ§eriyor.
        self.str_to_int = vocab
        # ters eÅŸleÅŸme oluÅŸturuluyor: sayÄ±dan kelimeye ulaÅŸmak iÃ§in
        self.int_to_str = {i: s for s, i in vocab.items()}

    def encode(self, text):
        # Metni, noktalama iÅŸaretlerine ve boÅŸluklara gÃ¶re parÃ§alÄ±yoruz.
        preprocessed = re.split(r"([,.:;?_!\"()\']|--|\s)", text)
        # BoÅŸluklardan ve gereksiz boÅŸ stringlerden kurtuluyoruz.
        preprocessed = [item.strip() for item in preprocessed if item.strip()]
        # Her kelimeyi veya sembolÃ¼, vocab iÃ§indeki sayÄ±sal karÅŸÄ±lÄ±ÄŸÄ±na Ã§eviriyoruz.
        ids = [self.str_to_int[s] for s in preprocessed]
        
        # SonuÃ§ olarak sayÄ±lardan oluÅŸan bir liste dÃ¶nÃ¼yor.
        return ids

    def decode(self, ids):
        # SayÄ± listesini tekrar kelimelere Ã§eviriyoruz.
        text = " ".join([self.int_to_str[i] for i in ids])
        # Noktalama iÅŸaretlerinden Ã¶nceki gereksiz boÅŸluklarÄ± temizliyoruz.
        text = re.sub(r'\s+([,.:;?_!\"()\'])', r'\1', text)
        return text


# ğŸ”¹ Bu sÄ±nÄ±f, ilkine Ã§ok benziyor.
# Tek farkÄ±: sÃ¶zlÃ¼kte olmayan kelimeleri yakalayÄ±p "<|unk|>" (bilinmeyen) etiketiyle deÄŸiÅŸtiriyor.
class SimpleTokenizerV2:
    def __init__(self, vocab):
        self.str_to_int = vocab
        self.int_to_str = {i: s for s, i in vocab.items()}

    def encode(self, text):
        preprocessed = re.split(r"([,.:;?_!\"()\']|--|\s)", text)
        preprocessed = [item.strip() for item in preprocessed if item.strip()]

        # EÄŸer bir kelime vocab iÃ§inde yoksa "<|unk|>" olarak iÅŸaretliyoruz.
        preprocessed = [
            item if item in self.str_to_int
            else "<|unk|>" for item in preprocessed
        ]

        ids = [self.str_to_int[s] for s in preprocessed]
        return ids

    def decode(self, ids):
        text = " ".join([self.int_to_str[i] for i in ids])
        text = re.sub(r'\s+([,.:;?_!\"()\'])', r'\1', text)
        return text
